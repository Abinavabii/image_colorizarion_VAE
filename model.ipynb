{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8dcce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vae_encoder(input_dim, output_dim):\n",
    "\n",
    "    global K\n",
    "    K.clear_session()\n",
    "\n",
    "    encoder_input = Input(shape = input_dim, name = 'encoder_input')\n",
    "    x = encoder_input\n",
    "\n",
    "    conv1 = Conv2D( 8 , kernel_size=( 5 , 5 ) , strides=1 )( x )\n",
    "    conv1 = LeakyReLU()( conv1 )\n",
    "    conv1 = Conv2D( 16 , kernel_size=( 3 , 3 ) , strides=1)( conv1 )\n",
    "    conv1 = LeakyReLU()( conv1 )\n",
    "    conv1 = Conv2D( 16 , kernel_size=( 3 , 3 ) , strides=1)( conv1 )\n",
    "    conv1 = LeakyReLU()( conv1 )\n",
    "\n",
    "    conv2 = Conv2D( 16 , kernel_size=( 5 , 5 ) , strides=1)( conv1 )\n",
    "    conv2 = LeakyReLU()( conv2 )\n",
    "    conv2 = Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1 )( conv2 )\n",
    "    conv2 = LeakyReLU()( conv2 )\n",
    "    conv2 = Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1 )( conv2 )\n",
    "    conv2 = LeakyReLU()( conv2 )\n",
    "\n",
    "    conv3 = Conv2D( 32 , kernel_size=( 5 , 5 ) , strides=1 )( conv2 )\n",
    "    conv3 = LeakyReLU()( conv3 )\n",
    "    conv3 = Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1 )( conv3 )\n",
    "    conv3 = LeakyReLU()( conv3 )\n",
    "    conv3 = Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1 )( conv3 )\n",
    "    conv3 = LeakyReLU()( conv3 )\n",
    "\n",
    " \n",
    "    shape_before_flattening = K.int_shape(conv3)[1:]\n",
    "\n",
    "    x = Flatten()(conv3)\n",
    "\n",
    "    mean_mu = Dense(64, name = 'mu')(x)\n",
    "    log_var = Dense(64, name = 'log_var')(x)\n",
    "\n",
    "  \n",
    "    z = Sampling()([mean_mu, log_var])\n",
    "    cshape1 = tf.shape(conv1)[2]\n",
    "    cshape2 = tf.shape(conv2)[2]\n",
    "    cshape3 = tf.shape(conv3)[2]\n",
    "\n",
    "    return encoder_input, [z, conv3, conv2, conv1], [cshape1, cshape2, cshape3], mean_mu, log_var , shape_before_flattening, Model(inputs = encoder_input, outputs = [mean_mu, log_var, z, conv3, conv2, conv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d17d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_encoder_input, vae_encoder_output, cshape, mean_mu, log_var, vae_shape_before_flattening, encoder  = build_vae_encoder(input_dim = INPUT_DIM,\n",
    "                                    output_dim = Z_DIM)\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb8e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(input_dim, shape_before_flattening):\n",
    "\n",
    "    # Define model input\n",
    "    decoder_input = Input(shape = (input_dim,) , name = 'decoder_input')\n",
    "    conv3 = Input(shape = (200,200,64,) , name = 'conv3')\n",
    "    conv2 = Input(shape = (208,208,32,) , name = 'conv2')\n",
    "    conv1 = Input(shape = (216,216,16,) , name = 'conv1')\n",
    "\n",
    "    x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "    x = Reshape(shape_before_flattening)(x)\n",
    "\n",
    "\n",
    "    concat_1 = Concatenate()( [ x , conv3 ] )\n",
    "    conv_up_3 = Conv2DTranspose( 64 , kernel_size=( 3 , 3 ) , strides=1 )( concat_1 )\n",
    "    conv_up_3 = LeakyReLU()( conv_up_3 )\n",
    "    conv_up_3 = Conv2DTranspose( 64 , kernel_size=( 3 , 3 ) , strides=1 )( conv_up_3 )\n",
    "    conv_up_3 = LeakyReLU()( conv_up_3 )\n",
    "    conv_up_3 = Conv2DTranspose( 32 , kernel_size=( 5 , 5 ) , strides=1 )( conv_up_3 )\n",
    "    conv_up_3 = LeakyReLU()( conv_up_3 )\n",
    "\n",
    "    concat_2 = Concatenate()( [ conv_up_3 , conv2 ] )\n",
    "    conv_up_2 = Conv2DTranspose( 32 , kernel_size=( 3 , 3 ) , strides=1 )( concat_2 )\n",
    "    conv_up_2 = LeakyReLU()( conv_up_2 )\n",
    "    conv_up_2 = Conv2DTranspose( 16 , kernel_size=( 3 , 3 ) , strides=1 )( conv_up_2 )\n",
    "    conv_up_2 = LeakyReLU()( conv_up_2 )\n",
    "    conv_up_2 = Conv2DTranspose( 16 , kernel_size=( 5 , 5 ) , strides=1 )( conv_up_2 )\n",
    "    conv_up_2 = LeakyReLU()( conv_up_2 )\n",
    "\n",
    "    concat_3 = Concatenate()( [ conv_up_2 , conv1 ] )\n",
    "    conv_up_1 = Conv2DTranspose( 16 , kernel_size=( 3 , 3 ) , strides=1 )( concat_3 )\n",
    "    conv_up_1 = LeakyReLU()( conv_up_1 )\n",
    "    conv_up_1 = Conv2DTranspose( 8 , kernel_size=( 3 , 3 ) , strides=1 )( conv_up_1 )\n",
    "    conv_up_1 = LeakyReLU()( conv_up_1 )\n",
    "    x = Conv2DTranspose( 2 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu')( conv_up_1 )\n",
    "\n",
    "\n",
    "    decoder_output = x\n",
    "\n",
    "    return [decoder_input, conv3, conv2, conv1], decoder_output, Model(inputs = [decoder_input, conv3, conv2, conv1], outputs = decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e997c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_decoder_input, vae_decoder_output, decoder = build_decoder(input_dim = Z_DIM,\n",
    "                                        shape_before_flattening = vae_shape_before_flattening\n",
    "                                        )\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7360f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00005\n",
    "def r_accuracy(img_original, img_reconstructed):\n",
    "    mse = tf.reduce_mean((img_original - img_reconstructed) ** 2)\n",
    "    pixel_max = 1.0\n",
    "    psnr = 20 * tf.math.log(pixel_max / tf.math.sqrt(mse))/tf.math.log(10.0)\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.r_accuracy_tracker = keras.metrics.Mean(name=\"r_accuracy\")\n",
    "        self.r_accuracy = r_accuracy\n",
    "\n",
    "\n",
    "    def call(self,x):\n",
    "        z_mean, z_log_var, z, conv3, conv2, conv1 = self.encoder(x)\n",
    "        reconstruction = self.decoder([z, conv3, conv2, conv1])\n",
    "        return reconstruction\n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.r_accuracy_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z, conv3, conv2, conv1 = self.encoder(x)\n",
    "            reconstruction = self.decoder([z, conv3, conv2, conv1])\n",
    "            reconstruction_loss = tf.reduce_mean(tf.math.square(y - reconstruction), axis=[1, 2, 3])\n",
    "            kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.math.square(z_mean) - tf.math.exp(z_log_var), axis = 1)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            #coorelation_loss = corr_loss(z)\n",
    "\n",
    "            total_loss = 10000*reconstruction_loss + kl_loss\n",
    "            r_accuracy = self.r_accuracy(y, reconstruction)\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.r_accuracy_tracker.update_state(r_accuracy)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"r_accuracy\": self.r_accuracy_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6935a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
